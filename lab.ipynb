{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3319648d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "\n",
    "# Construct the default API client.\n",
    "client = arxiv.Client()\n",
    "\n",
    "# Search for the 10 most recent articles matching the keyword \"quantum.\"\n",
    "search = arxiv.Search(\n",
    "  query = format_cat_query(cats),\n",
    "  max_results = 20,\n",
    "  sort_by = arxiv.SortCriterion.SubmittedDate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "25b1ab93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://export.arxiv.org/api/query?cat:cs.AI+OR+cat:cs.CL+OR+cat:cs.CV+OR+cat:cs.IR+OR+cat:cs.LG+OR+cat:cs.MA+OR+cat:cs.MM'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.query_url_format.format(format_cat_query(cats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5aeff554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "42b4940a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = client.results(search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7a2ef2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = [\n",
    "    'cs.AI', 'cs.CL', 'cs.CV', 'cs.IR', 'cs.LG', 'cs.MA', 'cs.MM',\n",
    "]\n",
    "\n",
    "\n",
    "class Client:\n",
    "    _instance = None\n",
    "    def __new__(cls):\n",
    "        if cls._instance is None:\n",
    "            cls._instance = arxiv.Client(page_size=2000)\n",
    "        return cls._instance\n",
    "\n",
    "\n",
    "def format_cat_query(cats):\n",
    "    res = []\n",
    "    for it in cats:\n",
    "        res.append(f'cat:{it}')\n",
    "    return '+OR+'.join(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "186f3cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = {\n",
    "    'publish_date': [],\n",
    "    'entry_id': [], \n",
    "    'title': [], \n",
    "    'abstract': [], \n",
    "    'primary_category': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b6c6f555",
   "metadata": {},
   "outputs": [],
   "source": [
    "for it in results:\n",
    "    datas['publish_date'].append(str(it.published).split()[0])\n",
    "    datas['entry_id'].append(it.entry_id)\n",
    "    datas['title'].append(it.title)\n",
    "    datas['abstract'].append(it.summary)\n",
    "    datas['primary_category'].append(it.primary_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "11b1ce08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>entry_id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>primary_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [publish_date, entry_id, title, abstract, primary_category]\n",
       "Index: []"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df = pd.DataFrame(datas)\n",
    "res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8715f961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entry_id': 'http://arxiv.org/abs/2312.13277v1',\n",
       " 'updated': datetime.datetime(2023, 12, 20, 18, 56, 45, tzinfo=datetime.timezone.utc),\n",
       " 'published': datetime.datetime(2023, 12, 20, 18, 56, 45, tzinfo=datetime.timezone.utc),\n",
       " 'title': 'Deep Learning on 3D Neural Fields',\n",
       " 'authors': [arxiv.Author('Pierluigi Zama Ramirez'),\n",
       "  arxiv.Author('Luca De Luigi'),\n",
       "  arxiv.Author('Daniele Sirocchi'),\n",
       "  arxiv.Author('Adriano Cardace'),\n",
       "  arxiv.Author('Riccardo Spezialetti'),\n",
       "  arxiv.Author('Francesco Ballerini'),\n",
       "  arxiv.Author('Samuele Salti'),\n",
       "  arxiv.Author('Luigi Di Stefano')],\n",
       " 'summary': 'In recent years, Neural Fields (NFs) have emerged as an effective tool for\\nencoding diverse continuous signals such as images, videos, audio, and 3D\\nshapes. When applied to 3D data, NFs offer a solution to the fragmentation and\\nlimitations associated with prevalent discrete representations. However, given\\nthat NFs are essentially neural networks, it remains unclear whether and how\\nthey can be seamlessly integrated into deep learning pipelines for solving\\ndownstream tasks. This paper addresses this research problem and introduces\\nnf2vec, a framework capable of generating a compact latent representation for\\nan input NF in a single inference pass. We demonstrate that nf2vec effectively\\nembeds 3D objects represented by the input NFs and showcase how the resulting\\nembeddings can be employed in deep learning pipelines to successfully address\\nvarious tasks, all while processing exclusively NFs. We test this framework on\\nseveral NFs used to represent 3D surfaces, such as unsigned/signed distance and\\noccupancy fields. Moreover, we demonstrate the effectiveness of our approach\\nwith more complex NFs that encompass both geometry and appearance of 3D objects\\nsuch as neural radiance fields.',\n",
       " 'comment': 'Extended version of the paper \"Deep Learning on Implicit Neural\\n  Representations of Shapes\" that was presented at ICLR 2023. arXiv admin note:\\n  text overlap with arXiv:2302.05438',\n",
       " 'journal_ref': None,\n",
       " 'doi': None,\n",
       " 'primary_category': 'cs.CV',\n",
       " 'categories': ['cs.CV'],\n",
       " 'links': [arxiv.Link('http://arxiv.org/abs/2312.13277v1', title=None, rel='alternate', content_type=None),\n",
       "  arxiv.Link('http://arxiv.org/pdf/2312.13277v1', title='pdf', rel='related', content_type=None)],\n",
       " 'pdf_url': 'http://arxiv.org/pdf/2312.13277v1',\n",
       " '_raw': {'id': 'http://arxiv.org/abs/2312.13277v1',\n",
       "  'guidislink': True,\n",
       "  'link': 'http://arxiv.org/abs/2312.13277v1',\n",
       "  'updated': '2023-12-20T18:56:45Z',\n",
       "  'updated_parsed': time.struct_time(tm_year=2023, tm_mon=12, tm_mday=20, tm_hour=18, tm_min=56, tm_sec=45, tm_wday=2, tm_yday=354, tm_isdst=0),\n",
       "  'published': '2023-12-20T18:56:45Z',\n",
       "  'published_parsed': time.struct_time(tm_year=2023, tm_mon=12, tm_mday=20, tm_hour=18, tm_min=56, tm_sec=45, tm_wday=2, tm_yday=354, tm_isdst=0),\n",
       "  'title': 'Deep Learning on 3D Neural Fields',\n",
       "  'title_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': '',\n",
       "   'value': 'Deep Learning on 3D Neural Fields'},\n",
       "  'summary': 'In recent years, Neural Fields (NFs) have emerged as an effective tool for\\nencoding diverse continuous signals such as images, videos, audio, and 3D\\nshapes. When applied to 3D data, NFs offer a solution to the fragmentation and\\nlimitations associated with prevalent discrete representations. However, given\\nthat NFs are essentially neural networks, it remains unclear whether and how\\nthey can be seamlessly integrated into deep learning pipelines for solving\\ndownstream tasks. This paper addresses this research problem and introduces\\nnf2vec, a framework capable of generating a compact latent representation for\\nan input NF in a single inference pass. We demonstrate that nf2vec effectively\\nembeds 3D objects represented by the input NFs and showcase how the resulting\\nembeddings can be employed in deep learning pipelines to successfully address\\nvarious tasks, all while processing exclusively NFs. We test this framework on\\nseveral NFs used to represent 3D surfaces, such as unsigned/signed distance and\\noccupancy fields. Moreover, we demonstrate the effectiveness of our approach\\nwith more complex NFs that encompass both geometry and appearance of 3D objects\\nsuch as neural radiance fields.',\n",
       "  'summary_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': '',\n",
       "   'value': 'In recent years, Neural Fields (NFs) have emerged as an effective tool for\\nencoding diverse continuous signals such as images, videos, audio, and 3D\\nshapes. When applied to 3D data, NFs offer a solution to the fragmentation and\\nlimitations associated with prevalent discrete representations. However, given\\nthat NFs are essentially neural networks, it remains unclear whether and how\\nthey can be seamlessly integrated into deep learning pipelines for solving\\ndownstream tasks. This paper addresses this research problem and introduces\\nnf2vec, a framework capable of generating a compact latent representation for\\nan input NF in a single inference pass. We demonstrate that nf2vec effectively\\nembeds 3D objects represented by the input NFs and showcase how the resulting\\nembeddings can be employed in deep learning pipelines to successfully address\\nvarious tasks, all while processing exclusively NFs. We test this framework on\\nseveral NFs used to represent 3D surfaces, such as unsigned/signed distance and\\noccupancy fields. Moreover, we demonstrate the effectiveness of our approach\\nwith more complex NFs that encompass both geometry and appearance of 3D objects\\nsuch as neural radiance fields.'},\n",
       "  'authors': [{'name': 'Pierluigi Zama Ramirez'},\n",
       "   {'name': 'Luca De Luigi'},\n",
       "   {'name': 'Daniele Sirocchi'},\n",
       "   {'name': 'Adriano Cardace'},\n",
       "   {'name': 'Riccardo Spezialetti'},\n",
       "   {'name': 'Francesco Ballerini'},\n",
       "   {'name': 'Samuele Salti'},\n",
       "   {'name': 'Luigi Di Stefano'}],\n",
       "  'author_detail': {'name': 'Luigi Di Stefano'},\n",
       "  'author': 'Luigi Di Stefano',\n",
       "  'arxiv_comment': 'Extended version of the paper \"Deep Learning on Implicit Neural\\n  Representations of Shapes\" that was presented at ICLR 2023. arXiv admin note:\\n  text overlap with arXiv:2302.05438',\n",
       "  'links': [{'href': 'http://arxiv.org/abs/2312.13277v1',\n",
       "    'rel': 'alternate',\n",
       "    'type': 'text/html'},\n",
       "   {'title': 'pdf',\n",
       "    'href': 'http://arxiv.org/pdf/2312.13277v1',\n",
       "    'rel': 'related',\n",
       "    'type': 'application/pdf'}],\n",
       "  'arxiv_primary_category': {'term': 'cs.CV',\n",
       "   'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "  'tags': [{'term': 'cs.CV',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None}]}}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d66f5640",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()\n",
    "\n",
    "results = arxiv.Search(\n",
    "    query=format_cat_query(cats),\n",
    "    sort_by=arxiv.SortCriterion.SubmittedDate\n",
    ")\n",
    "\n",
    "results = client.results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a92586ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mnext\u001b[39m(results))\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(next(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c1824bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for it in results:\n",
    "    res.append(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41d76a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a8a7e05",
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m search \u001b[38;5;241m=\u001b[39m arxiv\u001b[38;5;241m.\u001b[39mSearch(query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepresentation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m first_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(client\u001b[38;5;241m.\u001b[39mresults(search))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(first_result)\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "search = arxiv.Search(query = \"representation\")\n",
    "first_result = next(client.results(search))\n",
    "print(first_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adef1a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = arxiv.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27f7cabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = arxiv.Search(\n",
    "  query = \"quantum\",\n",
    "  #max_results = 10,\n",
    "  #sort_by = arxiv.SortCriterion.SubmittedDate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9057b184",
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m first_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(client\u001b[38;5;241m.\u001b[39mresults(search))\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "first_result = next(client.results(search))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dfdcca57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ab40dc8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d') < datetime.now().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836a3c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
